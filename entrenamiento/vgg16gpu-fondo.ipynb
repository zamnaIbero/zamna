{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings('ignore')\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.utils import shuffle\n\nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2023-08-01T02:06:11.598852Z","iopub.execute_input":"2023-08-01T02:06:11.599362Z","iopub.status.idle":"2023-08-01T02:06:11.606607Z","shell.execute_reply.started":"2023-08-01T02:06:11.599323Z","shell.execute_reply":"2023-08-01T02:06:11.605471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotImagenes(imagenes, size = (15, 8)):\n\n    fig, ax = plt.subplots(1, len(imagenes), figsize = size)\n    \n    for i in range(len(ax)):\n\n        ax[i].axis('off')\n        ax[i].imshow(imagenes[i], cmap = 'magma')\n\n    plt.show()\n\ndef vgg16Model(input = (256, 256, 1), output = 6):\n\n    kernel = (3, 3)\n\n    modelo = tf.keras.Sequential() # Modelo secuencial.\n    modelo.add(tf.keras.layers.Conv2D(64, kernel_size = kernel, padding = 'same', activation = 'relu', input_shape = input))\n    modelo.add(tf.keras.layers.Conv2D(64, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.MaxPooling2D(2, 2)) #\n\n    modelo.add(tf.keras.layers.Conv2D(128, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(128, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.MaxPooling2D(2, 2))\n\n    modelo.add(tf.keras.layers.Conv2D(256, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(256, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(256, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.MaxPooling2D(2, 2))\n\n    modelo.add(tf.keras.layers.Conv2D(512, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(512, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(512, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.MaxPooling2D(2, 2))\n\n    modelo.add(tf.keras.layers.Conv2D(512, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(512, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(512, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.MaxPooling2D(2, 2))\n\n    modelo.add(tf.keras.layers.Flatten())\n\n    modelo.add(tf.keras.layers.Dense(4096, activation = \"relu\"))\n    modelo.add(tf.keras.layers.Dense(4096, activation = \"relu\"))\n    modelo.add(tf.keras.layers.Dense(1000, activation = \"relu\"))\n    modelo.add(tf.keras.layers.Dense(256, activation = \"relu\"))\n    modelo.add(tf.keras.layers.Dense(output, activation = tf.keras.activations.softmax))\n\n    return modelo","metadata":{"execution":{"iopub.status.busy":"2023-08-01T02:06:11.612650Z","iopub.execute_input":"2023-08-01T02:06:11.613608Z","iopub.status.idle":"2023-08-01T02:06:11.635610Z","shell.execute_reply.started":"2023-08-01T02:06:11.613570Z","shell.execute_reply":"2023-08-01T02:06:11.634627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH_CSV = '/kaggle/input/fundusdiag/fundusDiag/full_df.csv'\n\ndf = pd.read_csv(PATH_CSV)\n\ndic = {'N' : [1, 0, 0, 0, 0],\n       'D' : [0, 1, 0, 0, 0],\n       'G' : [0, 0, 1, 0, 0],\n       'C' : [0, 0, 0, 1, 0],\n       'M' : [0, 0, 0, 0, 1]}\n\nfiles = df['filename'].to_list()\nlabeldf = [i[2] for i in df['labels'].to_list()]\n\nlabel = [dic[i] for i in labeldf if i == 'N' or i == 'D' or i == 'G' or i == 'C' or i == 'M'] # Etiquetas buenas.\n\nnormal = [i for i in range(0, len(labeldf)) if labeldf[i] == 'N']\ndiabetes = [i for i in range(0, len(labeldf)) if labeldf[i] == 'D']\nglaucoma = [i for i in range(0, len(labeldf)) if labeldf[i] == 'G']\ncataratas = [i for i in range(0, len(labeldf)) if labeldf[i] == 'C']\nmiopia = [i for i in range(0, len(labeldf)) if labeldf[i] == 'M']\n\nprint(len(normal), len(diabetes), len(glaucoma), len(cataratas), len(miopia))","metadata":{"execution":{"iopub.status.busy":"2023-08-01T02:06:11.638803Z","iopub.execute_input":"2023-08-01T02:06:11.639188Z","iopub.status.idle":"2023-08-01T02:06:11.695125Z","shell.execute_reply.started":"2023-08-01T02:06:11.639139Z","shell.execute_reply":"2023-08-01T02:06:11.694101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aux = '/kaggle/input/fundusdiag/fundusDiag/dataset256/'\n\ndef leerImagenes_tensor(path, files, toRead, label, MAX_IM = 1500):\n\n    im_faltantes = MAX_IM - len(toRead)\n    \n    rsz_rescale = tf.keras.Sequential([tf.keras.layers.Resizing(256, 256),\n                                       tf.keras.layers.Rescaling(1./255)]) # Resize y normalización de cada una de las imágenes.\n\n    nueva = tf.keras.Sequential([tf.keras.layers.RandomFlip(\"horizontal\"), # Modelo para generar nuevas imágenes.\n                                 tf.keras.layers.RandomRotation(factor = (-0.10, 0.10)),\n                                 tf.keras.layers.RandomContrast(factor = (0, 1))])\n\n    if im_faltantes <= 0:\n\n        im = [cv2.imread(aux + files[toRead[i]]) for i in range(0, MAX_IM)]\n        rsz_im = [tf.image.rgb_to_grayscale(rsz_rescale(i)).numpy() for i in im] # Reescalamiento y reescalamiento.\n\n        print(\"listo!\")\n\n        return [[i, label] for i in rsz_im]\n\n    elif im_faltantes > 0 :\n\n        im = [cv2.imread(aux + files[toRead[i]]) for i in range(0, len(toRead))]\n        rsz_im = [tf.image.rgb_to_grayscale(rsz_rescale(i)).numpy() for i in im] # Reescalamiento y reescalamiento.\n        extra_im = [nueva(rsz_im[np.random.randint(0, len(toRead))]).numpy() for i in range(0, im_faltantes)] # Imágenes extra.\n\n        total_im = np.concatenate((rsz_im, extra_im), axis = 0) # Dataset completo.\n\n        print(\"listo!\")\n\n        return [[i, label] for i in total_im] # Imagen con su label.\n\nlabels = [[1, 0, 0, 0, 0],\n          [0, 1, 0, 0, 0],\n          [0, 0, 1, 0, 0],\n          [0, 0, 0, 1, 0],\n          [0, 0, 0, 0, 1]]\n\ntoread = [normal, diabetes, glaucoma, cataratas, miopia]\n\n\ndata = [leerImagenes_tensor(aux, files, toread[i], labels[i]) for i in range(0, len(toread))] # Imágenes y labels.\n\nprint(\"Shape de los datos {}\".format(np.shape(data)))\n\ndiv = int(len(data[0]) * 0.8) # Número de imágenes (división 80 - 20)\ntest = len(data[0]) - div\n\nprint(\"División {}\".format(div))","metadata":{"execution":{"iopub.status.busy":"2023-08-01T02:06:11.696525Z","iopub.execute_input":"2023-08-01T02:06:11.697093Z","iopub.status.idle":"2023-08-01T02:08:04.104311Z","shell.execute_reply.started":"2023-08-01T02:06:11.697059Z","shell.execute_reply":"2023-08-01T02:08:04.103244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shape = (256, 256, 1)\nsalida = len(data)\n\nlr = 0.1\nep = 60\nn = 1\nes = EarlyStopping(monitor=\"val_loss\", patience = 20)\n\nmodelos, resultados = [], []\n\ncallbacks_list = [es]","metadata":{"execution":{"iopub.status.busy":"2023-08-01T02:08:04.105912Z","iopub.execute_input":"2023-08-01T02:08:04.106534Z","iopub.status.idle":"2023-08-01T02:08:04.113055Z","shell.execute_reply.started":"2023-08-01T02:08:04.106497Z","shell.execute_reply":"2023-08-01T02:08:04.111926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define tand get the number os devices. \nstrategy = tf.distribute.MirroredStrategy()\nprint('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))","metadata":{"execution":{"iopub.status.busy":"2023-08-01T02:08:04.116393Z","iopub.execute_input":"2023-08-01T02:08:04.116838Z","iopub.status.idle":"2023-08-01T02:08:04.464077Z","shell.execute_reply.started":"2023-08-01T02:08:04.116803Z","shell.execute_reply":"2023-08-01T02:08:04.462870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0, n): # Número de entrenamientos.\n\n    print(\"Entrenamiento: {}\".format(i + 1))\n\n    aux_train, aux_test = [i[0:div] for i in data], [i[div:len(i)] for i in data] # Separación de train y test de cada una de las clases.\n    train, test = aux_train[0], aux_test[0] # Primer set de imágenes.\n\n    for i in range(1, len(data)): # Construimos el dataset.\n\n        train, test = np.concatenate((train, aux_train[i]), axis = 0), np.concatenate((test, aux_test[i]), axis = 0) # Concatenamos todo el dataset.\n\n    train, test = shuffle(train), shuffle(test) # Shuffle de los datos de entrenamiento y prueba.\n\n    img_train, img_test = np.array([train[i][0] for i in range(len(train))]), np.array([test[i][0] for i in range(len(test))]) # Imágenes de entrenamiento y testeo.\n    lbl_train, lbl_test = np.array([train[i][1] for i in range(len(train))]), np.array([test[i][1] for i in range(len(test))]) # Etiquetas de entrenamiento y testeo.\n\n    with strategy.scope():\n        \n        modelo = vgg16Model(output = salida) # Creamos el modelo.\n\n    modelo.compile(optimizer = SGD(learning_rate = lr, decay = lr/ep),\n                  loss = 'categorical_crossentropy',\n                  metrics = ['accuracy'])\n\n    historia = modelo.fit(img_train,\n                          lbl_train,\n                          epochs = ep,\n                          batch_size = 64 * strategy.num_replicas_in_sync,\n                          validation_data = (img_test, lbl_test),\n                          callbacks = callbacks_list)\n\n    resultados.append(historia)\n    modelos.append(modelo)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T02:08:04.465538Z","iopub.execute_input":"2023-08-01T02:08:04.465935Z","iopub.status.idle":"2023-08-01T03:34:10.569122Z","shell.execute_reply.started":"2023-08-01T02:08:04.465894Z","shell.execute_reply":"2023-08-01T03:34:10.568146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir '/kaggle/working/GPU_f01/'\n!mkdir '/kaggle/working/GPU_f01/history/'\n!mkdir '/kaggle/working/GPU_f01/model'","metadata":{"execution":{"iopub.status.busy":"2023-08-01T03:34:10.572112Z","iopub.execute_input":"2023-08-01T03:34:10.572722Z","iopub.status.idle":"2023-08-01T03:34:14.179192Z","shell.execute_reply.started":"2023-08-01T03:34:10.572681Z","shell.execute_reply":"2023-08-01T03:34:14.177775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keys = resultados[0].history.keys()\n\nPATH = '/kaggle/working/GPU_f01/history/' # Path para guardar los resultados.\n\nfor i in range(0, len(resultados)):\n    \n    for j in keys: # Recorremos todas las keys de los modelos.\n        \n        PATH_AUX = PATH + 'modelo_1_'.format(i + 1) + j + '.txt'\n        \n        with open(PATH_AUX, 'w') as f:\n            \n            for k in resultados[i].history[j]:\n                \n                f.write(str(k) + '\\n')","metadata":{"execution":{"iopub.status.busy":"2023-08-01T03:34:14.181607Z","iopub.execute_input":"2023-08-01T03:34:14.186848Z","iopub.status.idle":"2023-08-01T03:34:14.198101Z","shell.execute_reply.started":"2023-08-01T03:34:14.186802Z","shell.execute_reply":"2023-08-01T03:34:14.197215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH_MODELOS = '/kaggle/working/GPU_f01/model/'\n\nfor i in range(0, len(modelos)):\n    \n    modelos[i].save(PATH_MODELOS + 'modelo001_1'.format(i + 1) + '.h5')\n#     conv = tf.lite.TFLiteConverter.from_saved_model(PATH_MODELOS + 'modelo01_{}'.format(i + 1))\n#     tflite = conv.convert()\n    \n#     with open(PATH_MODELOS + 'modelo01_{}/'.format(i + 1) + 'modelo01_{}.tflite'.format(i + 1), 'wb') as f:\n    \n#         f.write(tflite)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T03:34:14.203153Z","iopub.execute_input":"2023-08-01T03:34:14.204252Z","iopub.status.idle":"2023-08-01T03:34:16.828037Z","shell.execute_reply.started":"2023-08-01T03:34:14.204216Z","shell.execute_reply":"2023-08-01T03:34:16.826986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"holA\")","metadata":{"execution":{"iopub.status.busy":"2023-08-01T03:34:16.829857Z","iopub.execute_input":"2023-08-01T03:34:16.830258Z","iopub.status.idle":"2023-08-01T03:34:16.836185Z","shell.execute_reply.started":"2023-08-01T03:34:16.830223Z","shell.execute_reply":"2023-08-01T03:34:16.835231Z"},"trusted":true},"execution_count":null,"outputs":[]}]}