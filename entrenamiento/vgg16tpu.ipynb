{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings('ignore')\n\nimport os\nimport cv2\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\n\nfrom keras.optimizers import SGD, Adam\n\nfrom keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2023-08-03T01:25:38.032860Z","iopub.execute_input":"2023-08-03T01:25:38.033155Z","iopub.status.idle":"2023-08-03T01:26:21.438538Z","shell.execute_reply.started":"2023-08-03T01:25:38.033129Z","shell.execute_reply":"2023-08-03T01:26:21.437532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Funciones útiles.\n\ndef leerImagenes(path, label, im = 500, shape = (256, 256, 1)): # Para leer.\n    \n    im = [cv2.imread(path + os.listdir(path)[i]) for i in range(0, im)] # Leemos.\n    im = [cv2.cvtColor(cv2.resize(i, shape), cv2.COLOR_BGR2GRAY) for i in im] # Resize y blanco/negro.\n    \n    return [[i/np.max(i), label] for i in im] # Normalización y agregamos la label.\n\ndef leerImagenes_tensor(path, label, im = 500, shape = (256, 256), MAX_IM = 1800): # Para leer imágenes pero ocupando tensors.\n    \n    max_im = np.max([len(os.listdir(i)) for i in PATH_IM]) # Número máximo de imágenes.\n    lista_im = os.listdir(path)\n    im_faltantes = MAX_IM - len(lista_im) # Imágenes faltantes de cada clase.\n    \n    im = [cv2.imread(path + lista_im[i]) for i in range(0, len(lista_im))] # Leemos las imágenes.\n    \n    rsz_rescale = tf.keras.Sequential([tf.keras.layers.Resizing(256, 256),\n                                       tf.keras.layers.Rescaling(1./255)]) # Resize y normalización de cada una de las imágenes.\n    \n    rsz_im = [tf.image.rgb_to_grayscale(rsz_rescale(i)).numpy() for i in im] # Reescalamiento y reescalamiento.\n    \n    nueva = tf.keras.Sequential([tf.keras.layers.RandomFlip(\"horizontal\"), # Modelo para generar nuevas imágenes.\n                                 tf.keras.layers.RandomRotation(factor = (-0.10, 0.10)),\n                                 tf.keras.layers.RandomContrast(factor = (0, 1))])\n    \n    extra_im = [nueva(rsz_im[np.random.randint(0, len(lista_im))]).numpy() for i in range(0, im_faltantes)] # Imágenes extra.\n    \n    total_im = np.concatenate((rsz_im, extra_im), axis = 0) # Dataset completo.\n    \n    return [[i, label] for i in total_im] # Imagen con su label.\n\ndef vgg16Model(input = (256, 256, 1), output = 6):\n    \n    kernel = (3, 3)\n    \n    modelo = tf.keras.Sequential() # Modelo secuencial.\n    modelo.add(tf.keras.layers.Conv2D(64, kernel_size = kernel, padding = 'same', activation = 'relu', input_shape = input))\n    modelo.add(tf.keras.layers.Conv2D(64, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.MaxPooling2D(2, 2)) #\n    \n    modelo.add(tf.keras.layers.Conv2D(128, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(128, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.MaxPooling2D(2, 2))\n    \n    modelo.add(tf.keras.layers.Conv2D(256, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(256, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(256, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.MaxPooling2D(2, 2))\n    \n    modelo.add(tf.keras.layers.Conv2D(512, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(512, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(512, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.MaxPooling2D(2, 2))\n    \n    modelo.add(tf.keras.layers.Conv2D(512, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(512, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.Conv2D(512, kernel_size = kernel, padding = 'same', activation = 'relu'))\n    modelo.add(tf.keras.layers.MaxPooling2D(2, 2))\n    \n    modelo.add(tf.keras.layers.Flatten())\n    \n    modelo.add(tf.keras.layers.Dense(4096, activation = \"relu\"))\n    modelo.add(tf.keras.layers.Dense(4096, activation = \"relu\"))\n    modelo.add(tf.keras.layers.Dense(1000, activation = \"relu\"))\n    modelo.add(tf.keras.layers.Dense(256, activation = \"relu\"))\n    modelo.add(tf.keras.layers.Dense(6, activation = tf.keras.activations.softmax))\n    \n    return modelo\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-03T01:26:21.440571Z","iopub.execute_input":"2023-08-03T01:26:21.441075Z","iopub.status.idle":"2023-08-03T01:26:21.472671Z","shell.execute_reply.started":"2023-08-03T01:26:21.441042Z","shell.execute_reply":"2023-08-03T01:26:21.471866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lectura de los datos.\n\nnp.random.seed(42)\n\nPATH_GENERAL = '/kaggle/input/enfpulm/enfermedadesPulmonares/'\npaths = sorted(os.listdir(PATH_GENERAL))\n\nPATH_IM = [PATH_GENERAL + i + '/' for i in paths] # Paths de las imágenes.\n\nlabels = [[1, 0, 0, 0, 0, 0],\n          [0, 1, 0, 0, 0, 0],\n          [0, 0, 1, 0, 0, 0],\n          [0, 0, 0, 1, 0, 0],\n          [0, 0, 0, 0, 1, 0],\n          [0, 0, 0, 0, 0, 1]] # Labels.\n\nprint([len(os.listdir(i)) for i in PATH_IM])\n\ndata = [leerImagenes_tensor(PATH_IM[i], labels[i], MAX_IM = 2000) for i in range(0, len(PATH_IM))] # Imágenes y labels.\n\nprint(\"Shape de los datos {}\".format(np.shape(data)))\n\ndiv = int(len(data[0]) * 0.8) # Número de imágenes (división 80 - 20)\ntest = len(data[0]) - div\n\nprint(\"División {}\".format(div))","metadata":{"execution":{"iopub.status.busy":"2023-08-03T01:26:21.473794Z","iopub.execute_input":"2023-08-03T01:26:21.474093Z","iopub.status.idle":"2023-08-03T01:29:08.721728Z","shell.execute_reply.started":"2023-08-03T01:26:21.474067Z","shell.execute_reply":"2023-08-03T01:29:08.720683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n     # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\n    \nexcept ValueError: tpu = None\n\nif tpu:\n    \n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    st = tf.distribute.experimental.TPUStrategy(tpu)\n    \nelse:\n    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    st = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", st.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T01:29:08.723943Z","iopub.execute_input":"2023-08-03T01:29:08.724248Z","iopub.status.idle":"2023-08-03T01:29:13.378693Z","shell.execute_reply.started":"2023-08-03T01:29:08.724220Z","shell.execute_reply":"2023-08-03T01:29:13.377781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\nBATCH = 32 * st.num_replicas_in_sync\nN_ITER = 250\n\nn, lr, ep = 3, 0.1, 60\n\n\nes = EarlyStopping(monitor=\"val_loss\", patience = 15)\n\nmodelos, resultados = [], []\n\ncallbacks_list = [es]\n\nfor i in range(0, n): # Número de entrenamientos.\n    \n    print(\"Entrenamiento: {}\".format(i + 1))\n    \n    aux_train, aux_test = [i[0:div] for i in data], [i[div:len(i)] for i in data] # Separación de train y test de cada una de las clases.\n    train, test = aux_train[0], aux_test[0] # Primer set de imágenes.\n    \n    for i in range(1, len(data)): # Construimos el dataset.\n\n        train, test = np.concatenate((train, aux_train[i]), axis = 0), np.concatenate((test, aux_test[i]), axis = 0) # Concatenamos todo el dataset.\n\n    #train, test = shuffle(train), shuffle(test) # Shuffle de los datos de entrenamiento y prueba.\n\n    img_train, img_test = np.array([train[i][0] for i in range(len(train))]), np.array([test[i][0] for i in range(len(test))]) # Imágenes de entrenamiento y testeo.\n    lbl_train, lbl_test = np.array([train[i][1] for i in range(len(train))]), np.array([test[i][1] for i in range(len(test))]) # Etiquetas de entrenamiento y testeo.\n    \n    # Una vez seperados los datos convertimos a datasets de tensorflow.\n    \n    train_dataset = (tf.data.Dataset.from_tensor_slices((img_train.astype(np.float32),\n                                                         lbl_train.astype(np.float32)))\n                    .repeat()\n                    .shuffle(2048)\n                    .batch(BATCH)\n                    .prefetch(AUTO))\n    \n    val_dataset = (tf.data.Dataset.from_tensor_slices((img_test.astype(np.float32),\n                                                       lbl_test.astype(np.float32)))\n                   .shuffle(2048)\n                   .batch(BATCH)\n                   .prefetch(AUTO))\n    \n    test_dataset = (tf.data.Dataset.from_tensor_slices(img_test.astype(np.float32))\n                    .batch(BATCH))\n    \n    # Entrenamos el modelo con TPU\n    \n    with st.scope(): modelo = vgg16Model() # Creamos el modelo.\n        \n    modelo.compile(optimizer = SGD(learning_rate = lr, decay = lr/ep),\n                  loss = 'categorical_crossentropy',\n                  metrics = ['accuracy'])\n    \n    historia = modelo.fit(train_dataset,\n                          steps_per_epoch = N_ITER,\n                          epochs = ep,\n                          validation_data = (val_dataset),\n                          callbacks = callbacks_list)\n    \n    resultados.append(historia)\n    modelos.append(modelo)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T01:29:13.379904Z","iopub.execute_input":"2023-08-03T01:29:13.380220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir '/kaggle/working/TPU_rad01/'\n!mkdir '/kaggle/working/TPU_rad01/history/'\n!mkdir '/kaggle/working/TPU_rad01/model'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keys = resultados[0].history.keys()\n\nPATH = '/kaggle/working/TPU_rad01/history/' # Path para guardar los resultados.\n\nfor i in range(0, len(resultados)):\n    \n    for j in keys: # Recorremos todas las keys de los modelos.\n        \n        PATH_AUX = PATH + 'modelo_{}_'.format(i + 1) + j + '.txt'\n        \n        with open(PATH_AUX, 'w') as f:\n            \n            for k in resultados[i].history[j]:\n                \n                f.write(str(k) + '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH_MODELOS = '/kaggle/working/TPU_rad01/model/'\n\nfor i in range(0, len(modelos)):\n    \n    modelos[i].save(PATH_MODELOS + 'modelo01_{}'.format(i + 1))\n    conv = tf.lite.TFLiteConverter.from_saved_model(PATH_MODELOS + 'modelo01_{}'.format(i + 1))\n    tflite = conv.convert()\n    \n    with open(PATH_MODELOS + 'modelo01_{}/'.format(i + 1) + 'modelo01_{}.tflite'.format(i + 1), 'wb') as f:\n    \n        f.write(tflite)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"hola\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}